import argparse
import shutil

import onnx
import pyrealsense2
from ultralytics import YOLO
import cv2
import numpy as np
from pathlib import Path
import os
import torch

# åŠ¨æ€å¯¼å…¥TensorRTç›¸å…³åº“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    import tensorrt as trt
    import pycuda.driver as cuda
    import pycuda.autoinit
    TENSORRT_AVAILABLE = True
except ImportError:
    TENSORRT_AVAILABLE = False
    print("âš ï¸  TensorRTæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ ‡å‡†PyTorchæ¨¡å‹")

# åŠ¨æ€å¯¼å…¥ONNX Runtimeç›¸å…³åº“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False
    print("âš ï¸  ONNX Runtimeæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ ‡å‡†PyTorchæ¨¡å‹")

from utils.calibrationManager import apply_perspective_correction, camera_to_chess_position


class ChessPieceDetectorSeparate():
    def __init__(self, model_path='yolov8s.pt'):
        """
        åˆå§‹åŒ–æ£‹å­æ£€æµ‹å™¨ - çº¢é»‘æ£‹å­åˆ†åˆ«è¯†åˆ«
        æ”¯æŒ.ptã€.trt/.engineå’Œ.onnxæ ¼å¼
        """
        self.model_path = model_path
        self.is_trt_model = model_path.endswith(('.trt', '.engine'))
        self.is_onnx_model = model_path.endswith('.onnx')
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {self.device}")

        if self.is_trt_model and TENSORRT_AVAILABLE:
            print("ğŸ”§ åŠ è½½TensorRTä¼˜åŒ–æ¨¡å‹...")
            self.model = self._load_trt_model(model_path)
        elif self.is_onnx_model and ONNX_AVAILABLE:
            print("ğŸ”§ åŠ è½½ONNXæ¨¡å‹...")
            self.model = self._load_onnx_model(model_path)
        else:
            print("ğŸ”§ åŠ è½½æ ‡å‡†YOLOæ¨¡å‹...")
            self.model = YOLO(model_path)
            # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            self.model.to(self.device)

        # çº¢é»‘åŒæ–¹å„7ç§æ£‹å­
        self.class_names = ["A","B", "C", "K", "N", "P", "R", "a", "b", "c", "k", "n", "p", "r"]

        # ä¸ºæ¯ç§æ£‹å­åˆ†é…ä¸åŒé¢œè‰²
        self.colors = [
            # çº¢æ–¹æ£‹å­ - çº¢è‰²ç³»
            (0, 0, 255),    # red_general - çº¯çº¢
            (0, 50, 255),   # red_advisor - æ©™çº¢
            (0, 100, 255),  # red_elephant - æ©™è‰²
            (0, 150, 255),  # red_horse - æ©™é»„
            (0, 200, 255),  # red_chariot - é»„æ©™
            (0, 255, 255),  # red_cannon - é»„è‰²
            (100, 255, 255),# red_soldier - æµ…é»„

            # é»‘æ–¹æ£‹å­ - è“è‰²ç³»/é»‘è‰²ç³»
            (255, 0, 0),    # black_general - è“è‰²
            (255, 50, 0),   # black_advisor - æ·±è“
            (255, 100, 0),  # black_elephant - é›è“
            (255, 150, 0),  # black_horse - ç´«è“
            (255, 200, 0),  # black_chariot - é’è“
            (255, 255, 0),  # black_cannon - é’è‰²
            (128, 128, 0)   # black_soldier - ç°è‰²
        ]


    def _load_trt_model(self, engine_path):
        """
        åŠ è½½TensorRTå¼•æ“æ¨¡å‹
        """
        if not TENSORRT_AVAILABLE:
            raise RuntimeError("TensorRTåº“æœªå®‰è£…ï¼Œæ— æ³•åŠ è½½TensorRTæ¨¡å‹")

        try:
            # åˆ›å»ºTensorRTè¿è¡Œæ—¶
            TRT_LOGGER = trt.Logger(trt.Logger.WARNING)
            with open(engine_path, 'rb') as f:
                runtime = trt.Runtime(TRT_LOGGER)
                self.engine = runtime.deserialize_cuda_engine(f.read())

            # åˆ›å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
            self.context = self.engine.create_execution_context()

            # åˆ†é…GPUç¼“å†²åŒº
            self.inputs = []
            self.outputs = []
            self.bindings = []

            for binding in self.engine:
                binding_idx = self.engine.get_binding_index(binding)
                if binding_idx == -1:
                    print(f"âŒ æœªæ‰¾åˆ°ç»‘å®š: {binding}")
                    continue

                # è·å–ç»‘å®šç»´åº¦
                dims = self.engine.get_binding_shape(binding_idx)
                size = trt.volume(dims) * self.engine.max_batch_size * np.dtype(np.float32).itemsize

                # åˆ†é…GPUå†…å­˜
                gpu_mem = cuda.mem_alloc(size)
                self.bindings.append(int(gpu_mem))

                if self.engine.binding_is_input(binding_idx):
                    self.inputs.append({'mem': gpu_mem, 'shape': dims, 'name': binding})
                else:
                    self.outputs.append({'mem': gpu_mem, 'shape': dims, 'name': binding})

            print("âœ… TensorRTæ¨¡å‹åŠ è½½æˆåŠŸ")
            return None  # TRTæ¨¡å‹ä¸éœ€è¦ä¿å­˜ä¸ºself.model
        except Exception as e:
            print(f"âš ï¸  TensorRTæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°æ ‡å‡†PyTorchæ¨¡å‹")
            self.is_trt_model = False
            model = YOLO(self.model_path.replace('.trt', '.pt').replace('.engine', '.pt'))
            model.to(self.device)
            return model

    def _load_onnx_model(self, onnx_path):
        """
        åŠ è½½ONNXæ¨¡å‹
        """
        if not ONNX_AVAILABLE:
            raise RuntimeError("ONNX Runtimeæœªå®‰è£…ï¼Œæ— æ³•åŠ è½½ONNXæ¨¡å‹")

        try:
            # æ ¹æ®CUDAå¯ç”¨æ€§é€‰æ‹©æ‰§è¡Œæä¾›è€…
            providers = []
            if torch.cuda.is_available():
                # å°è¯•ä¸åŒçš„CUDAæä¾›è€…
                cuda_providers = [
                    'CUDAExecutionProvider',
                    'TensorrtExecutionProvider',  # å¦‚æœå®‰è£…äº†TensorRT
                    'CPUExecutionProvider'
                ]
                # æ£€æŸ¥å“ªäº›æä¾›è€…å¯ç”¨
                available_providers = ort.get_available_providers()
                for provider in cuda_providers:
                    if provider in available_providers:
                        providers.append(provider)
                        break  # åªä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„æä¾›è€…
            else:
                providers = ['CPUExecutionProvider']

            print(f"ğŸ”§ ä½¿ç”¨ONNXæä¾›è€…: {providers}")

            # åˆ›å»ºä¼šè¯é€‰é¡¹
            sess_options = ort.SessionOptions()
            sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_EXTENDED
            sess_options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL
            sess_options.intra_op_num_threads = 4  # é™åˆ¶çº¿ç¨‹æ•°ä»¥å‡å°‘å†…å­˜ä½¿ç”¨

            self.onnx_session = ort.InferenceSession(
                onnx_path,
                sess_options=sess_options,
                providers=providers
            )
            print("âœ… ONNXæ¨¡å‹åŠ è½½æˆåŠŸ")
            return None
        except Exception as e:
            print(f"âš ï¸  ONNXæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°æ ‡å‡†PyTorchæ¨¡å‹")
            self.is_onnx_model = False
            # å°è¯•æ‰¾åˆ°å¯¹åº”çš„.ptæ–‡ä»¶
            pt_path = onnx_path.replace('.onnx', '.pt')
            if not os.path.exists(pt_path):
                # å¦‚æœæ²¡æœ‰.ptæ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤çš„yolov8s.pt
                pt_path = 'yolov8s.pt'
            model = YOLO(pt_path)
            model.to(self.device)
            return model

    def _trt_inference(self, image):
        """
        ä½¿ç”¨TensorRTå¼•æ“æ‰§è¡Œæ¨ç†
        """
        try:
            # é¢„å¤„ç†å›¾åƒ
            input_shape = self.inputs[0]['shape']
            processed_img = self._preprocess_image(image, input_shape)

            # å°†è¾“å…¥æ•°æ®å¤åˆ¶åˆ°GPU
            cuda.memcpy_htod(self.inputs[0]['mem'], processed_img)

            # æ‰§è¡Œæ¨ç†
            self.context.execute_v2(bindings=self.bindings)

            # ä»GPUè·å–è¾“å‡º
            results = []
            for output in self.outputs:
                output_data = np.empty(output['shape'], dtype=np.float32)
                cuda.memcpy_dtoh(output_data, output['mem'])
                results.append(output_data)

            # åå¤„ç†ç»“æœï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“æ¨¡å‹è¾“å‡ºæ ¼å¼è¿›è¡Œè°ƒæ•´ï¼‰
            return self._postprocess_results(results, image.shape)

        except Exception as e:
            print(f"âš ï¸  TensorRTæ¨ç†å¤±è´¥: {e}")
            # å›é€€åˆ°æ ‡å‡†YOLOæ¨ç†
            model = YOLO(self.model_path.replace('.trt', '.pt').replace('.engine', '.pt'))
            model.to(self.device)
            return model(image)

    def _onnx_inference(self, image_path,conf_threshold,iou_threshold):
        """
        ä½¿ç”¨ONNXæ¨¡å‹æ‰§è¡Œæ¨ç†
        """
        try:
            # ç›´æ¥ä½¿ç”¨YOLOåŠ è½½ONNXæ¨¡å‹è¿›è¡Œæ¨ç†
            model = YOLO(self.model_path)
            results = model(
                image_path,
                conf=conf_threshold,
                iou=iou_threshold,
                imgsz=640,
                save=False,
                show=False,
                device='cpu' if not torch.cuda.is_available() else 0
            )
            return  results
        except Exception as e:
            print(f"âš ï¸  ONNXæ¨ç†å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ–¹æ³•: {e}")


    def _preprocess_image(self, image, input_shape):
        """
        é¢„å¤„ç†å›¾åƒä»¥é€‚é…æ¨¡å‹è¾“å…¥
        """
        # ç¡®ä¿è¾“å…¥å½¢çŠ¶æ­£ç¡®
        if len(input_shape) == 4:
            target_h, target_w = input_shape[2], input_shape[3]
        else:
            # é»˜è®¤ä½¿ç”¨640x640
            target_h, target_w = 640, 640

        # è°ƒæ•´å›¾åƒå¤§å°ï¼Œä¿æŒå®½é«˜æ¯”
        h, w = image.shape[:2]
        scale = min(target_w/w, target_h/h)
        new_w, new_h = int(w * scale), int(h * scale)

        resized = cv2.resize(image, (new_w, new_h))

        # åˆ›å»ºç”»å¸ƒå¹¶å±…ä¸­æ”¾ç½®å›¾åƒ
        canvas = np.full((target_h, target_w, 3), 114, dtype=np.uint8)
        pad_x, pad_y = (target_w - new_w) // 2, (target_h - new_h) // 2
        canvas[pad_y:pad_y+new_h, pad_x:pad_x+new_w] = resized

        # è½¬æ¢é¢œè‰²ç©ºé—´ (BGR to RGB)
        rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)

        # å½’ä¸€åŒ–
        normalized = rgb.astype(np.float32) / 255.0

        # è½¬æ¢ä¸ºCHWæ ¼å¼
        chw = np.transpose(normalized, (2, 0, 1))

        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
        batched = np.expand_dims(chw, axis=0)

        # è½¬æ¢ä¸ºè¿ç»­å†…å­˜å¸ƒå±€
        return np.ascontiguousarray(batched)

    def _postprocess_results(self, trt_outputs, original_shape):
        """
        åå¤„ç†TensorRTè¾“å‡ºç»“æœ
        æ³¨æ„ï¼šè¿™ä¸ªå®ç°éœ€è¦æ ¹æ®å…·ä½“æ¨¡å‹è¾“å‡ºæ ¼å¼è¿›è¡Œè°ƒæ•´
        """
        # è¿™é‡Œæ˜¯ä¸€ä¸ªç®€åŒ–çš„ç¤ºä¾‹å®ç°
        # å®é™…åº”ç”¨ä¸­éœ€è¦æ ¹æ®æ¨¡å‹çš„å…·ä½“è¾“å‡ºæ ¼å¼è¿›è¡Œè§£æ
        # ä¸ºä¿æŒå…¼å®¹æ€§ï¼Œæˆ‘ä»¬æš‚æ—¶å›é€€åˆ°æ ‡å‡†YOLOæ¨¡å‹
        print("âš ï¸  TensorRTåå¤„ç†æœªå®Œå…¨å®ç°ï¼Œå›é€€åˆ°æ ‡å‡†æ¨¡å‹")
        standard_model = YOLO(self.model_path.replace('.trt', '.pt').replace('.engine', '.pt'))
        standard_model.to(self.device)
        return standard_model(np.zeros(original_shape, dtype=np.uint8))
    def _postprocess_onnx_results(self, onnx_outputs, original_shape):
        """
        åå¤„ç†ONNXè¾“å‡ºç»“æœ
        """
        try:
            # ONNXæ¨¡å‹è¾“å‡ºé€šå¸¸æ˜¯è¾¹ç•Œæ¡†ã€ç±»åˆ«æ¦‚ç‡å’Œç½®ä¿¡åº¦
            # å‡è®¾è¾“å‡ºæ ¼å¼ä¸º [batch_size, num_boxes, 5 + num_classes]
            # å…¶ä¸­5è¡¨ç¤º [x, y, w, h, conf]ï¼Œnum_classesæ˜¯ç±»åˆ«æ•°é‡

            if not onnx_outputs or len(onnx_outputs) == 0:
                print("âš ï¸  ONNXè¾“å‡ºä¸ºç©º")
                # å›é€€åˆ°æ ‡å‡†YOLOæ¨¡å‹
                pt_path = self.model_path.replace('.onnx', '.pt')
                if not os.path.exists(pt_path):
                    pt_path = 'yolov8s.pt'
                model = YOLO(pt_path)
                model.to(self.device)
                return model(np.zeros(original_shape, dtype=np.uint8))

            # è·å–è¾“å‡ºæ•°æ®ï¼ˆé€šå¸¸æ˜¯è¾¹ç•Œæ¡†é¢„æµ‹ï¼‰
            output_data = onnx_outputs[0]  # å–ç¬¬ä¸€ä¸ªè¾“å‡º

            # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„YOLOç»“æœå¯¹è±¡ï¼Œä½¿å…¶ä¸æ ‡å‡†YOLOè¾“å‡ºå…¼å®¹
            class DetectionResult:
                def __init__(self, boxes):
                    self.boxes = boxes

            class Boxes:
                def __init__(self, data):
                    self.data = data
                    self.xyxy = self._convert_xyxy()
                    self.conf = self._extract_conf()
                    self.cls = self._extract_cls()

                def _convert_xyxy(self):
                    # å¦‚æœè¾“å‡ºæ˜¯ [x_center, y_center, width, height] æ ¼å¼ï¼Œè½¬æ¢ä¸º [x1, y1, x2, y2]
                    if len(self.data.shape) >= 2 and self.data.shape[1] >= 4:
                        xyxy = self.data.copy()
                        # è½¬æ¢ x_center, y_center, width, height -> x1, y1, x2, y2
                        xyxy[:, 0] = self.data[:, 0] - self.data[:, 2] / 2  # x1 = x_center - width/2
                        xyxy[:, 1] = self.data[:, 1] - self.data[:, 3] / 2  # y1 = y_center - height/2
                        xyxy[:, 2] = self.data[:, 0] + self.data[:, 2] / 2  # x2 = x_center + width/2
                        xyxy[:, 3] = self.data[:, 1] + self.data[:, 3] / 2  # y2 = y_center + height/2
                        return xyxy
                    return self.data

                def _extract_conf(self):
                    # å‡è®¾ç½®ä¿¡åº¦æ˜¯ç¬¬5åˆ—ï¼ˆç´¢å¼•4ï¼‰
                    if len(self.data.shape) >= 2 and self.data.shape[1] >= 5:
                        return self.data[:, 4:5]  # ä¿æŒäºŒç»´å½¢çŠ¶
                    return None

                def _extract_cls(self):
                    # å‡è®¾ç±»åˆ«ä¿¡æ¯ä»ç¬¬6åˆ—å¼€å§‹ï¼ˆç´¢å¼•5ï¼‰
                    if len(self.data.shape) >= 2 and self.data.shape[1] >= 6:
                        # è·å–æœ€é«˜æ¦‚ç‡çš„ç±»åˆ«ç´¢å¼•
                        class_probs = self.data[:, 5:]
                        return np.argmax(class_probs, axis=1).reshape(-1, 1)
                    return None

                def __len__(self):
                    return len(self.data) if self.data is not None else 0

                def __iter__(self):
                    """å®ç°è¿­ä»£å™¨æ¥å£ï¼Œä½¿Boxeså¯¹è±¡å¯è¿­ä»£"""
                    # åˆ›å»ºä¸€ä¸ªç®€å•çš„Boxå¯¹è±¡æ¥æ¨¡æ‹ŸYOLOçš„boxå¯¹è±¡
                    class Box:
                        def __init__(self, data_row):
                            self.data = data_row
                            self.xyxy = self._extract_xyxy()
                            self.conf = self._extract_conf()
                            self.cls = self._extract_cls()

                        def _extract_xyxy(self):
                            class XYXY:
                                def __init__(self, data):
                                    self.data = data

                                def __getitem__(self, idx):
                                    return self.data[idx:idx+1] if idx == 0 else None

                                def cpu(self):
                                    class CPUWrapper:
                                        def __init__(self, data):
                                            self.data = data

                                        def numpy(self):
                                            return self.data
                                    return CPUWrapper(self.data)

                                def numpy(self):
                                    return self.data
                            return XYXY(self.data[0:4])

                        def _extract_conf(self):
                            class Conf:
                                def __init__(self, conf_data):
                                    self.data = conf_data

                                def __getitem__(self, idx):
                                    return self.data[idx:idx+1] if idx == 0 else None

                                def cpu(self):
                                    class CPUWrapper:
                                        def __init__(self, data):
                                            self.data = data

                                        def numpy(self):
                                            return self.data
                                    return CPUWrapper(self.data)

                                def numpy(self):
                                    return self.data
                            return Conf(self.data[4:5]) if len(self.data) >= 5 else None

                        def _extract_cls(self):
                            class Cls:
                                def __init__(self, cls_data):
                                    self.data = cls_data

                                def __getitem__(self, idx):
                                    return self.data[idx:idx+1] if idx == 0 else None

                                def cpu(self):
                                    class CPUWrapper:
                                        def __init__(self, data):
                                            self.data = data

                                        def numpy(self):
                                            return self.data
                                    return CPUWrapper(self.data)

                                def numpy(self):
                                    return self.data
                            return Cls(self.data[5:6]) if len(self.data) >= 6 else None

                    # ä¸ºæ¯ä¸ªæ•°æ®è¡Œåˆ›å»ºBoxå¯¹è±¡
                    for i in range(len(self.data)):
                        yield Box(self.data[i])

                def cpu(self):
                    return self

                def numpy(self):
                    return self

            # å¤„ç†è¾“å‡ºæ•°æ®
            if len(output_data.shape) == 3:  # [batch, num_boxes, features]
                # å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„ç»“æœ
                boxes_data = output_data[0]
            elif len(output_data.shape) == 2:  # [num_boxes, features]
                boxes_data = output_data
            else:
                print(f"âš ï¸  ä¸æ”¯æŒçš„ONNXè¾“å‡ºå½¢çŠ¶: {output_data.shape}")
                # å›é€€åˆ°æ ‡å‡†YOLOæ¨¡å‹
                pt_path = self.model_path.replace('.onnx', '.pt')
                if not os.path.exists(pt_path):
                    pt_path = 'yolov8s.pt'
                model = YOLO(pt_path)
                model.to(self.device)
                return model(np.zeros(original_shape, dtype=np.uint8))

            # è¿‡æ»¤æ‰æ— æ•ˆçš„è¾¹ç•Œæ¡†ï¼ˆå¯ä»¥æ·»åŠ æ›´å¤šçš„åå¤„ç†é€»è¾‘ï¼‰
            # è¿™é‡Œç®€å•åœ°ä¿ç•™æ‰€æœ‰æ£€æµ‹ç»“æœ
            valid_indices = np.where(np.any(boxes_data != 0, axis=1))[0]
            filtered_boxes = boxes_data[valid_indices] if len(valid_indices) > 0 else boxes_data

            # åˆ›å»ºBoxeså¯¹è±¡
            boxes_obj = Boxes(filtered_boxes)

            # åˆ›å»ºDetectionResultå¯¹è±¡
            result_obj = DetectionResult(boxes_obj)

            # è¿”å›ç»“æœåˆ—è¡¨ï¼Œæ¨¡æ‹Ÿæ ‡å‡†YOLOè¾“å‡ºæ ¼å¼
            return [result_obj]

        except Exception as e:
            print(f"âš ï¸  ONNXåå¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            # å›é€€åˆ°æ ‡å‡†YOLOæ¨¡å‹
            pt_path = self.model_path.replace('.onnx', '.pt')
            if not os.path.exists(pt_path):
                pt_path = 'yolov8s.pt'
            model = YOLO(pt_path)
            model.to(self.device)
            return model(np.zeros(original_shape, dtype=np.uint8))


    def convert_to_trt(self, output_path=None, imgsz=640, half=True):
        """
        å°†ONNXæ¨¡å‹è½¬æ¢ä¸ºTensorRTæ ¼å¼

        Args:
            output_path: è¾“å‡ºTensorRTæ¨¡å‹è·¯å¾„
            imgsz: è¾“å…¥å›¾åƒå°ºå¯¸
            half: æ˜¯å¦ä½¿ç”¨FP16ç²¾åº¦
        """
        if not self.model_path.endswith('.pt'):
            print("âŒ  åªæœ‰PyTorchæ¨¡å‹(.pt)å¯ä»¥è½¬æ¢ä¸ºTensorRTæ ¼å¼")
            return None
        # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
        if not torch.cuda.is_available():
            print("âŒ  CUDAä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒTensorRTè½¬æ¢")
            return None
        if output_path is None:
            model_name = Path(self.model_path).stem
            output_dir = Path(self.model_path).parent
            output_path = str(output_dir / f"{model_name}.trt")

        try:
            # ä½¿ç”¨ultralyticsæä¾›çš„å¯¼å‡ºåŠŸèƒ½
            model = YOLO(self.model_path)

            # å¯¼å‡ºä¸ºTensorRTæ ¼å¼
            model.export(
                format='engine',
                imgsz=imgsz,
                half=half,  # ä½¿ç”¨FP16ç²¾åº¦
                device=0 if torch.cuda.is_available() else None,  # ä½¿ç”¨GPU 0æˆ–CPU
                verbose=True
            )

            # é‡å‘½åç”Ÿæˆçš„æ–‡ä»¶
            generated_path = self.model_path.replace('.pt', '.engine')
            if os.path.exists(generated_path):
                shutil.move(generated_path, output_path)

            print(f"âœ… æ¨¡å‹å·²æˆåŠŸè½¬æ¢ä¸ºTensorRTæ ¼å¼: {output_path}")
            return output_path

        except Exception as e:
            print(f"âŒ æ¨¡å‹è½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None


    def convert_to_onnx(self, output_path=None, imgsz=640, dynamic=False):
        """
        å°†YOLOæ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼

        Args:
            output_path: è¾“å‡ºONNXæ¨¡å‹è·¯å¾„
            imgsz: è¾“å…¥å›¾åƒå°ºå¯¸
            dynamic: æ˜¯å¦ä½¿ç”¨åŠ¨æ€è¾“å…¥å°ºå¯¸
        """
        if not self.model_path.endswith('.pt'):
            print("âŒ  åªæœ‰PyTorchæ¨¡å‹(.pt)å¯ä»¥è½¬æ¢ä¸ºONNXæ ¼å¼")
            return None

        if output_path is None:
            # ä¿å­˜åœ¨ä¸.ptæ–‡ä»¶ç›¸åŒçš„è·¯å¾„ä¸‹
            model_name = Path(self.model_path).stem
            output_dir = Path(self.model_path).parent
            output_path = str(output_dir / f"{model_name}.onnx")

        try:
            # ä½¿ç”¨ultralyticsæä¾›çš„å¯¼å‡ºåŠŸèƒ½
            model = YOLO(self.model_path)

            # å¯¼å‡ºä¸ºONNXæ ¼å¼ï¼Œæ·»åŠ æ›´å¤šå…¼å®¹æ€§é€‰é¡¹
            export_args = {
                'format': 'onnx',
                'imgsz': imgsz,
                'dynamic': False,  # æ ¹æ®__main__ä¸­çš„è®¾ç½®æ”¹ä¸ºFalse
                'simplify': True,
                'opset': 17,  # ä½¿ç”¨ä¸__main__ä¸­ç›¸åŒçš„opsetç‰ˆæœ¬
                'device': 0 if torch.cuda.is_available() else 'cpu'
            }

            # å¦‚æœæ˜¯CPUç¯å¢ƒï¼Œæ·»åŠ é¢å¤–çš„å…¼å®¹æ€§é€‰é¡¹
            if not torch.cuda.is_available():
                export_args['opset'] = 11  # æ›´ä½çš„opsetç‰ˆæœ¬
                export_args['half'] = False  # ç¦ç”¨åŠç²¾åº¦

            model.export(**export_args)

            # é‡å‘½åç”Ÿæˆçš„æ–‡ä»¶
            generated_path = self.model_path.replace('.pt', '.onnx')
            if os.path.exists(generated_path):
                os.rename(generated_path, output_path)

            # è®¾ç½®ONNX IRç‰ˆæœ¬
            self.set_onnx_ir_version(output_path)

            print(f"âœ… æ¨¡å‹å·²æˆåŠŸè½¬æ¢ä¸ºONNXæ ¼å¼: {output_path}")
            return output_path

        except Exception as e:
            print(f"âŒ æ¨¡å‹è½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def set_onnx_ir_version(self, onnx_path, ir_version=8):
        """
        è®¾ç½®ONNXæ¨¡å‹çš„IRç‰ˆæœ¬

        Args:
            onnx_path: ONNXæ¨¡å‹è·¯å¾„
            ir_version: ç›®æ ‡IRç‰ˆæœ¬
        """
        try:
            model = onnx.load(onnx_path)
            model.ir_version = ir_version
            onnx.save(model, onnx_path)
            print(f"âœ… ONNX IRç‰ˆæœ¬å·²è®¾ç½®ä¸º: {ir_version}")
        except Exception as e:
            print(f"âš ï¸  è®¾ç½®ONNX IRç‰ˆæœ¬å¤±è´¥: {e}")


    def train(self, data_yaml='yaml/data.yaml', epochs=300, imgsz=640):
        """
        è®­ç»ƒæ£‹å­æ£€æµ‹æ¨¡å‹
        """
        # ç¡®ä¿ä½¿ç”¨çš„æ˜¯.ptæ¨¡å‹è¿›è¡Œè®­ç»ƒ
        train_model_path = self.model_path
        if self.model_path.endswith(('.trt', '.engine', '.onnx')):
            train_model_path = self._get_pt_model_path()

        model = YOLO(train_model_path)
        # æ ¹æ®CUDAå¯ç”¨æ€§é€‰æ‹©è®¾å¤‡
        device = 0 if torch.cuda.is_available() else 'cpu'
        model.train(
            data=data_yaml,
            epochs=epochs,
            imgsz=imgsz,
            batch=16,
            device=device,
            name='chess_piece_detection_separate'
        )

    def _get_pt_model_path(self):
        """
        è·å–å¯¹åº”çš„.ptæ¨¡å‹è·¯å¾„
        """
        if self.model_path.endswith(('.trt', '.engine')):
            return self.model_path.replace('.trt', '.pt').replace('.engine', '.pt')
        elif self.model_path.endswith('.onnx'):
            return self.model_path.replace('.onnx', '.pt')
        return self.model_path

    def _run_inference(self, image_path,image, conf_threshold=0.5, iou_threshold=0.25):
        """
        æ ¹æ®æ¨¡å‹ç±»å‹æ‰§è¡Œæ¨ç†
        """
        if self.is_trt_model and TENSORRT_AVAILABLE:
            return self._trt_inference(image)
        elif self.is_onnx_model and ONNX_AVAILABLE:
            return self._onnx_inference(image_path, conf_threshold=0.5, iou_threshold=0.25)
        else:
            return self.model(image, conf=conf_threshold, iou=iou_threshold)

    def detect(self, image_path, conf_threshold=0.3, iou_threshold=0.45, save_path='result.jpg'):
        """
        æ£€æµ‹å›¾åƒä¸­çš„æ£‹å­å¹¶ä¿å­˜ç»“æœå›¾ç‰‡
        æ ¹æ®__main__éƒ¨åˆ†ä¼˜åŒ–æ¨ç†æµç¨‹

        :param image_path: è¾“å…¥å›¾åƒè·¯å¾„
        :param conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        :param iou_threshold: IOU é˜ˆå€¼
        :param save_path: ä¿å­˜ç»“æœå›¾åƒçš„è·¯å¾„
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
        # æ‰§è¡Œæ£€æµ‹
        results = self._run_inference(image_path,image, conf_threshold, iou_threshold)

        # å¯è§†åŒ–æ£€æµ‹ç»“æœ
        vis_image = self.visualize_detections(image, results)

        # ä¿å­˜ç»“æœå›¾åƒ
        cv2.imwrite(save_path, vis_image)
        print(f"âœ… æ£€æµ‹ç»“æœå·²ä¿å­˜è‡³: {save_path}")
    def visualize_detections(self, image, results):
        """
        å¯è§†åŒ–æ£€æµ‹ç»“æœï¼ˆå¢åŠ å»é‡é€»è¾‘ï¼‰
        """
        # å¤åˆ¶å›¾åƒç”¨äºç»˜åˆ¶
        img_vis = image.copy()

        # è·å–æ£€æµ‹ç»“æœ
        boxes = None
        if hasattr(results, '__len__') and len(results) > 0:
            boxes = results[0].boxes if hasattr(results[0], 'boxes') else None
        else:
            boxes = results[0].boxes if hasattr(results, '__len__') and hasattr(results[0], 'boxes') else None

        if boxes is not None and len(boxes) > 0:
            # æ·»åŠ å»é‡é€»è¾‘ï¼šå¯¹ç›¸åŒç±»åˆ«çš„é‡å æ¡†è¿›è¡Œèšç±»
            filtered_boxes = self._filter_duplicate_detections(boxes)

            # éå†æ¯ä¸ªæ£€æµ‹åˆ°çš„æ£‹å­
            for box in filtered_boxes:
                # è·å–è¾¹ç•Œæ¡†åæ ‡
                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                conf = float(box.conf[0].cpu().numpy())
                cls = int(box.cls[0].cpu().numpy())

                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                color = self.colors[cls]
                cv2.rectangle(img_vis, (x1, y1), (x2, y2), color, 2)

                # ç»˜åˆ¶æ ‡ç­¾
                label = f'{self.class_names[cls]} {conf:.2f}'
                cv2.putText(img_vis, label, (x1, y1-10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        return img_vis

    def _filter_duplicate_detections(self, boxes, iou_threshold=0.5):
        """
        è¿‡æ»¤é‡å¤æ£€æµ‹æ¡†
        """
        if len(boxes) <= 1:
            return boxes

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        confidences = [float(box.conf[0].cpu().numpy()) for box in boxes]
        sorted_indices = sorted(range(len(confidences)), key=lambda i: confidences[i], reverse=True)

        keep_boxes = []
        used_indices = set()

        for i in sorted_indices:
            if i in used_indices:
                continue

            current_box = boxes[i]
            keep_boxes.append(current_box)
            used_indices.add(i)

            # è®¡ç®—ä¸å½“å‰æ¡†çš„IOUï¼Œæ ‡è®°é‡å çš„ä½ç½®ä¿¡åº¦æ¡†
            for j in sorted_indices:
                if j in used_indices:
                    continue

                iou = self._calculate_iou(current_box.xyxy[0].cpu().numpy(),
                                        boxes[j].xyxy[0].cpu().numpy())
                if iou > iou_threshold:
                    used_indices.add(j)

        return keep_boxes

    def _calculate_iou(self, box1, box2):
        """
        è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IOU
        """
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])

        intersection = max(0, x2 - x1) * max(0, y2 - y1)
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - intersection

        return intersection / union if union > 0 else 0

    def save_image_with_keypoints(self, image_path, output_path, half_board="red", conf_threshold=0.5, iou_threshold=0.4):
        """
        æ£€æµ‹å›¾åƒä¸­çš„å…³é”®ç‚¹å¹¶ä¿å­˜å¸¦å…³é”®ç‚¹çš„å›¾åƒ

        :param image_path: è¾“å…¥å›¾åƒè·¯å¾„
        :param output_path: è¾“å‡ºå›¾åƒä¿å­˜è·¯å¾„
        :param half_board: åŠåŒºç±»å‹ ("red" æˆ– "black")
        :param conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        :param iou_threshold: IOUé˜ˆå€¼
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")

        # å¤åˆ¶å›¾åƒç”¨äºç»˜åˆ¶
        img_vis = image.copy()

        try:
            # å¯¼å…¥å‚æ•°æ–‡ä»¶ä¸­çš„å›ºå®šåæ ‡
            from parameters import CHESS_BOARD_R, CHESS_BOARD_B

            # æ ¹æ®half_boardå‚æ•°é€‰æ‹©ä½¿ç”¨å“ªä¸€ç»„å›ºå®šåæ ‡
            if half_board == "red":
                # ä½¿ç”¨çº¢æ–¹åŠç›˜çš„å››ä¸ªè§’ç‚¹åæ ‡
                fixed_points = CHESS_BOARD_R
            else:  # black
                # ä½¿ç”¨é»‘æ–¹åŠç›˜çš„å››ä¸ªè§’ç‚¹åæ ‡
                fixed_points = CHESS_BOARD_B

            # ç»˜åˆ¶å›ºå®šçš„å…³é”®ç‚¹
            for i, (x, y) in enumerate(fixed_points):
                # ç»˜åˆ¶å…³é”®ç‚¹ï¼ˆä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†ï¼‰
                cv2.circle(img_vis, (int(x), int(y)), 8, (0, 255, 0), -1)  # ç»¿è‰²åœ†ç‚¹
                # æ·»åŠ å…³é”®ç‚¹ç¼–å·
                cv2.putText(img_vis, str(i), (int(x)+10, int(y)+10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)


            # ç»˜åˆ¶æ£‹ç›˜è¾¹ç•Œæ¡†
            pts = np.array(fixed_points, np.int32)
            pts = pts.reshape((-1, 1, 2))
            cv2.polylines(img_vis, [pts], True, (255, 0, 0), 2)

        except ImportError:
            print("âš ï¸  æ— æ³•å¯¼å…¥å‚æ•°æ–‡ä»¶ï¼Œè·³è¿‡å›ºå®šå…³é”®ç‚¹ç»˜åˆ¶")

        # ä¿å­˜ç»“æœå›¾åƒ
        cv2.imwrite(output_path, img_vis)
        print(f"âœ… å¸¦å…³é”®ç‚¹çš„å›¾åƒå·²ä¿å­˜è‡³: {output_path}")
    def extract_chessboard_layout_with_height(self, image, chess_points, half_board="red",
                                              conf_threshold=0.5, iou_threshold=0.4):
        """
        ä»å›¾åƒä¸­æå–æ£‹ç›˜å¸ƒå±€

        :param image: è¾“å…¥å›¾åƒ
        :param half_board: åŠåŒºç±»å‹ ("red" æˆ– "black")
        :param conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        :param iou_threshold: IOUé˜ˆå€¼
        :return: æ£‹ç›˜å¸ƒå±€çŸ©é˜µå’Œæ£€æµ‹ç»“æœ
        """
        if image is None:
            # å¦‚æœæ²¡æœ‰å›¾åƒï¼Œè¿”å›ç©ºæ£‹ç›˜
            empty_layout = [['.' for _ in range(9)] for _ in range(5)]
            return empty_layout, None, {}

        # æ‰§è¡Œæ£€æµ‹
        results = self._run_inference(image, conf_threshold, iou_threshold)

        # åˆå§‹åŒ–5x9æ£‹ç›˜ï¼ˆåŠä¸ªæ£‹ç›˜ï¼‰
        chess_layout = [['.' for _ in range(9)] for _ in range(5)]
        points_center = {}
        # å­˜å‚¨æ£‹å­é«˜åº¦ä¿¡æ¯
        piece_heights = {}

        # è·å–æ£€æµ‹ç»“æœ
        boxes = results[0].boxes if hasattr(results, '__len__') and hasattr(results[0], 'boxes') else None

        if boxes is not None and len(boxes) > 0:
            # æå–æ‰€æœ‰æ£€æµ‹æ¡†ä¿¡æ¯ç”¨äºå»é‡
            detections = []
            for box in boxes:
                # è·å–è¾¹ç•Œæ¡†åæ ‡å’Œç±»åˆ«
                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                conf = float(box.conf[0].cpu().numpy())
                cls = int(box.cls[0].cpu().numpy())

                # è®¡ç®—æ£‹å­ä¸­å¿ƒç‚¹
                center_x = (x1 + x2) // 2
                center_y = (y1 + y2) // 2

                # å°†å›¾åƒåæ ‡è½¬æ¢ä¸ºæ£‹ç›˜åæ ‡
                if half_board == 'red':
                    chess_pos = camera_to_chess_position(center_x, center_y, chess_points)
                else:
                    chess_pos = camera_to_chess_position(center_x, center_y, chess_points)

                if chess_pos is not None:
                    detections.append({
                        'box': box,
                        'chess_pos': chess_pos,
                        'conf': conf,
                        'cls': cls,
                        'center': (center_x, center_y),
                    })

            # æŒ‰ç…§æ£‹ç›˜ä½ç½®å¯¹æ£€æµ‹ç»“æœè¿›è¡Œåˆ†ç»„
            position_detections = {}
            for detection in detections:
                row, col = detection['chess_pos']
                position_key = (row, col)

                if position_key not in position_detections:
                    position_detections[position_key] = []
                position_detections[position_key].append(detection)

            # å¯¹æ¯ä¸ªä½ç½®çš„å¤šä¸ªæ£€æµ‹ç»“æœè¿›è¡Œå»é‡ï¼Œä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„
            filtered_detections = []
            for position_key, detections_list in position_detections.items():
                # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œä¿ç•™æœ€é«˜çš„
                best_detection = max(detections_list, key=lambda x: x['conf'])
                filtered_detections.append(best_detection)

            # éå†å»é‡åçš„æ£€æµ‹ç»“æœ
            for detection in filtered_detections:
                row, col = detection['chess_pos']
                cls = detection['cls']
                # å°†æ£€æµ‹åˆ°çš„æ£‹å­æ”¾å…¥æ£‹ç›˜å¸ƒå±€
                chess_layout[row][col] = self.class_names[cls]
                if half_board == 'red':
                    points_center[f"{9-row}{8-col}"] = detection['center']
                else:
                    points_center[f"{row}{col}"] = detection['center']

        return chess_layout, results,points_center

    def detect_objects_with_height(self, image, depth_frame=None, conf_threshold=0.5, iou_threshold=0.4, mat=None):
        """
        æ£€æµ‹å›¾åƒä¸­çš„ç‰©ä½“å¹¶è·å–å…¶ä½ç½®å’Œé«˜åº¦ä¿¡æ¯ï¼Œä¸æ¶‰åŠæ£‹ç›˜é€»è¾‘

        :param image: è¾“å…¥å›¾åƒ
        :param depth_frame: æ·±åº¦å¸§æ•°æ®ï¼ˆå¯é€‰ï¼‰
        :param conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        :param iou_threshold: IOUé˜ˆå€¼
        :return: ç‰©ä½“æ£€æµ‹ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«ç±»åˆ«ã€è¾¹ç•Œæ¡†åæ ‡å’Œé«˜åº¦ä¿¡æ¯
        """
        if image is None:
            return []

        # æ‰§è¡Œæ£€æµ‹
        results = self._run_inference(image, conf_threshold, iou_threshold)

        # å­˜å‚¨æ£€æµ‹åˆ°çš„ç‰©ä½“ä¿¡æ¯
        objects_info = []

        # è·å–æ£€æµ‹ç»“æœ
        boxes = results[0].boxes if hasattr(results, '__len__') and hasattr(results[0], 'boxes') else None

        if boxes is not None and len(boxes) > 0:
            # éå†æ¯ä¸ªæ£€æµ‹åˆ°çš„ç‰©ä½“
            detections = []
            for box in boxes:
                # è·å–è¾¹ç•Œæ¡†åæ ‡å’Œç±»åˆ«
                x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                conf = float(box.conf[0].cpu().numpy())
                cls = int(box.cls[0].cpu().numpy())

                # è®¡ç®—ç‰©ä½“ä¸­å¿ƒç‚¹
                center_x = (x1 + x2) // 2
                center_y = (y1 + y2) // 2

                # åˆ›å»ºç‰©ä½“ä¿¡æ¯å­—å…¸
                detection = {
                    'box': box,
                    'class_id': cls,
                    'class_name': self.class_names[cls] if cls < len(self.class_names) else f"unknown_{cls}",
                    'bbox': (x1, y1, x2, y2),
                    'center': (center_x, center_y),
                    'confidence': conf
                }

                # è·å–é«˜åº¦ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº†æ·±åº¦å¸§ï¼‰
                if depth_frame is not None:
                    try:
                        # è·å–è¯¥ç‚¹çš„æ·±åº¦å€¼
                        if mat is not None:
                            x, y = apply_perspective_correction(mat, center_x, center_y)
                        else:
                            x, y = center_x, center_y
                        depth_value = depth_frame.get_distance(x, y)
                        if depth_value == 0:
                            depth_value = depth_frame.get_distance(x+5, y+5)
                        depth_intrinsics = depth_frame.profile.as_video_stream_profile().intrinsics
                        camera_xyz = pyrealsense2.rs2_deproject_pixel_to_point(
                            depth_intrinsics,
                            [float(center_x), float(center_y)],
                            depth_value
                        )
                        camera_xyz = np.round(np.array(camera_xyz), 3)
                        # detection['center'] = (camera_xyz[0], camera_xyz[1])
                        detection['height'] = camera_xyz[2]
                    except Exception as e:
                        print(f"Error processing depth information: {e}")
                        detection['height'] = None
                else:
                    detection['height'] = None

                detections.append(detection)

            # æŒ‰ç½®ä¿¡åº¦æ’åº
            detections.sort(key=lambda x: x['confidence'], reverse=True)

            # å»é‡é€»è¾‘ï¼šä¿ç•™ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ç»“æœ
            filtered_detections = []
            used_boxes = []

            for detection in detections:
                current_box = detection['bbox']
                is_overlap = False

                # æ£€æŸ¥å½“å‰æ£€æµ‹æ¡†æ˜¯å¦ä¸å·²ä¿ç•™çš„æ£€æµ‹æ¡†é‡å 
                for used_box in used_boxes:
                    iou = self._calculate_iou(
                        [current_box[0], current_box[1], current_box[2], current_box[3]],
                        [used_box[0], used_box[1], used_box[2], used_box[3]]
                    )
                    if iou > iou_threshold:
                        is_overlap = True
                        break

                # å¦‚æœä¸é‡å ï¼Œåˆ™ä¿ç•™è¯¥æ£€æµ‹ç»“æœ
                if not is_overlap:
                    filtered_detections.append(detection)
                    used_boxes.append(current_box)

            objects_info = filtered_detections

        return objects_info, results



# åœ¨ä¸»ç¨‹åºä¸­ä½¿ç”¨
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_path', type=str,
                        default='runs/detect/chess_piece_detection_separate/weights/best.pt',
                        help='æ¨¡å‹è·¯å¾„ (.pt æˆ– .trt/.engine æˆ– .onnx)')
    parser.add_argument('--convert_to', default='onnx', action='store_true',
                        help='å°†.ptæ¨¡å‹è½¬æ¢ä¸ºTensorRT/onnxæ ¼å¼')
    parser.add_argument('--imgsz', type=int, default=640,
                        help='è¾“å…¥å›¾åƒå°ºå¯¸')
    parser.add_argument('--conf_threshold', type=float, default=0.45,
                        help='ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--iou_threshold', type=float, default=0.25,
                        help='IOUé˜ˆå€¼')

    args = parser.parse_args()
    # åˆ›å»ºæ£€æµ‹å™¨å®ä¾‹
    detector = ChessPieceDetectorSeparate(args.model_path)
    # detector.train()

    # å¦‚æœéœ€è¦è½¬æ¢æ¨¡å‹ä¸ºTensorRT
    if args.convert_to=='trt' and args.model_path.endswith('.pt'):
        trt_model_path = detector.convert_to_trt(imgsz=args.imgsz)
        if trt_model_path:
            print(f"âœ… æ¨¡å‹è½¬æ¢æˆåŠŸ: {trt_model_path}")
            detector = ChessPieceDetectorSeparate(trt_model_path)
        else:
            print("âŒ æ¨¡å‹è½¬æ¢å¤±è´¥")
    #
    # å¦‚æœéœ€è¦è½¬æ¢æ¨¡å‹ä¸ºONNX
    elif args.convert_to=='onnx' and args.model_path.endswith('.pt'):
        onnx_model_path = detector.convert_to_onnx(imgsz=args.imgsz)
        if onnx_model_path:
            print(f"âœ… æ¨¡å‹è½¬æ¢æˆåŠŸ: {onnx_model_path}")
            detector = ChessPieceDetectorSeparate(onnx_model_path)
        else:
            print("âŒ æ¨¡å‹è½¬æ¢å¤±è´¥")

    # æ‰§è¡Œæ£€æµ‹
    detector.detect(
        "RS_20250913_114917.jpg",
        conf_threshold=args.conf_threshold,
        iou_threshold=args.iou_threshold,
        save_path="result_with_keypoints.jpg"
    )
